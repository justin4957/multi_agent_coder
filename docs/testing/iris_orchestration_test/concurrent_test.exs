# Concurrent Orchestration Test - Real Execution
# Run this with: mix run /tmp/contact_manager_test/concurrent_test.exs

require Logger

defmodule ConcurrentOrchestrationTest do
  @moduledoc """
  Tests concurrent task execution using Iris + Ollama integration.
  """

  def run do
    print_header()
    check_environment()
    prepare_tasks()
    execute_concurrent_test()
    analyze_results()
  end

  defp print_header do
    IO.puts("\n" <> IO.ANSI.cyan() <> "=" <> String.duplicate("=", 78) <> IO.ANSI.reset())
    IO.puts(IO.ANSI.cyan() <> "  IRIS + OLLAMA CONCURRENT ORCHESTRATION TEST" <> IO.ANSI.reset())
    IO.puts(IO.ANSI.cyan() <> "  Testing High-Performance Local LLM Pipeline" <> IO.ANSI.reset())
    IO.puts(IO.ANSI.cyan() <> "=" <> String.duplicate("=", 78) <> IO.ANSI.reset() <> "\n")
  end

  defp check_environment do
    IO.puts(IO.ANSI.yellow() <> "üîç Environment Check" <> IO.ANSI.reset())

    # Check Ollama
    case check_ollama() do
      {:ok, models} ->
        IO.puts(IO.ANSI.green() <> "  ‚úì Ollama running with #{length(models)} models" <> IO.ANSI.reset())
        Enum.each(models, fn model ->
          IO.puts("    ‚Ä¢ #{model}")
        end)

      {:error, reason} ->
        IO.puts(IO.ANSI.red() <> "  ‚úó Ollama check failed: #{inspect(reason)}" <> IO.ANSI.reset())
        IO.puts("\n  Please start Ollama: ollama serve")
        System.halt(1)
    end

    # Check Iris availability
    iris_available = Code.ensure_loaded?(Iris.Producer)
    if iris_available do
      IO.puts(IO.ANSI.green() <> "  ‚úì Iris module loaded" <> IO.ANSI.reset())
    else
      IO.puts(IO.ANSI.yellow() <> "  ‚ö† Iris not available, will use direct mode" <> IO.ANSI.reset())
    end

    # Check backend configuration
    backend = Application.get_env(:multi_agent_coder, :local_provider_backend, :direct)
    iris_enabled = Application.get_env(:multi_agent_coder, :iris_enabled, false)

    IO.puts("  ‚Ä¢ Backend: #{backend}")
    IO.puts("  ‚Ä¢ Iris enabled: #{iris_enabled}")
    IO.puts("")
  end

  defp check_ollama do
    try do
      response = Req.get!("http://localhost:11434/api/tags")
      models = response.body["models"] |> Enum.map(& &1["name"])
      {:ok, models}
    rescue
      e -> {:error, Exception.message(e)}
    end
  end

  defp prepare_tasks do
    IO.puts(IO.ANSI.yellow() <> "üìù Preparing Test Tasks" <> IO.ANSI.reset())

    tasks = [
      %{
        id: 1,
        name: "Contact Data Model",
        description: "Create Contact struct with validation"
      },
      %{
        id: 2,
        name: "Storage Module",
        description: "Implement JSON file persistence"
      },
      %{
        id: 3,
        name: "API Module",
        description: "Create contact management API"
      },
      %{
        id: 4,
        name: "CLI Interface",
        description: "Build interactive command-line UI"
      }
    ]

    Enum.each(tasks, fn task ->
      IO.puts("  Task #{task.id}: #{task.name}")
      IO.puts("    ‚îî‚îÄ #{task.description}")
    end)

    IO.puts("")
  end

  defp execute_concurrent_test do
    IO.puts(IO.ANSI.green() <> "üöÄ Executing Concurrent Test" <> IO.ANSI.reset())
    IO.puts(IO.ANSI.green() <> String.duplicate("-", 80) <> IO.ANSI.reset() <> "\n")

    # Read task specifications
    task_prompts = [
      File.read!("/tmp/contact_manager_test/task1_contact_model.md"),
      File.read!("/tmp/contact_manager_test/task2_storage.md"),
      File.read!("/tmp/contact_manager_test/task3_api.md"),
      File.read!("/tmp/contact_manager_test/task4_cli.md")
    ]

    # Execute tasks concurrently using Task.async
    start_time = System.monotonic_time(:millisecond)

    IO.puts("  ‚è≥ Launching 4 concurrent tasks...")

    tasks = task_prompts
    |> Enum.with_index(1)
    |> Enum.map(fn {prompt, index} ->
      Task.async(fn ->
        execute_single_task(index, prompt, start_time)
      end)
    end)

    # Wait for all tasks to complete
    results = Task.await_many(tasks, 300_000) # 5 minute timeout

    total_time = System.monotonic_time(:millisecond) - start_time

    IO.puts("\n" <> IO.ANSI.green() <> "‚úÖ All tasks completed!" <> IO.ANSI.reset())
    IO.puts("   Total execution time: #{total_time}ms (#{Float.round(total_time / 1000, 2)}s)\n")

    {results, total_time}
  end

  defp execute_single_task(task_id, prompt, start_time) do
    task_start = System.monotonic_time(:millisecond)
    relative_start = task_start - start_time

    IO.puts(IO.ANSI.cyan() <> "  [Task #{task_id}] Started at +#{relative_start}ms" <> IO.ANSI.reset())

    # Call the local provider (which uses Iris if configured)
    result = case MultiAgentCoder.Agent.Worker.execute_task(:local, prompt, %{}) do
      {:ok, response} ->
        task_end = System.monotonic_time(:millisecond)
        duration = task_end - task_start
        relative_end = task_end - start_time

        IO.puts(IO.ANSI.green() <> "  [Task #{task_id}] ‚úì Completed at +#{relative_end}ms (#{duration}ms duration)" <> IO.ANSI.reset())

        # Save output
        output_file = "/tmp/contact_manager_test/output/task#{task_id}.ex"
        File.mkdir_p!("/tmp/contact_manager_test/output")
        File.write!(output_file, response)

        {:ok, task_id, duration, byte_size(response)}

      {:error, reason} ->
        task_end = System.monotonic_time(:millisecond)
        duration = task_end - task_start

        IO.puts(IO.ANSI.red() <> "  [Task #{task_id}] ‚úó Failed: #{inspect(reason)}" <> IO.ANSI.reset())

        {:error, task_id, duration, reason}
    end

    result
  end

  defp analyze_results do
    IO.puts("\n" <> IO.ANSI.yellow() <> "üìä Performance Analysis" <> IO.ANSI.reset())
    IO.puts(IO.ANSI.yellow() <> String.duplicate("-", 80) <> IO.ANSI.reset())

    # Check if outputs were created
    output_dir = "/tmp/contact_manager_test/output"
    if File.exists?(output_dir) do
      files = File.ls!(output_dir)
      IO.puts("\n  Generated files: #{length(files)}")
      Enum.each(files, fn file ->
        path = Path.join(output_dir, file)
        size = File.stat!(path).size
        IO.puts("    ‚Ä¢ #{file} (#{size} bytes)")
      end)
    end

    IO.puts("\n" <> IO.ANSI.cyan() <> "üí° Iris Pipeline Benefits:" <> IO.ANSI.reset())
    IO.puts("  ‚Ä¢ Concurrent request processing via Broadway")
    IO.puts("  ‚Ä¢ Response caching for duplicate prompts")
    IO.puts("  ‚Ä¢ Circuit breakers and automatic failover")
    IO.puts("  ‚Ä¢ Load balancing across models (if configured)")
    IO.puts("  ‚Ä¢ Comprehensive telemetry and monitoring")

    IO.puts("\n" <> IO.ANSI.yellow() <> "üìà Expected Performance Gains:" <> IO.ANSI.reset())
    IO.puts("  ‚Ä¢ Concurrency: 100-1000x vs sequential")
    IO.puts("  ‚Ä¢ Throughput: 5-10x without cache, 20-50x with cache")
    IO.puts("  ‚Ä¢ Latency overhead: +5-10ms pipeline processing")

    IO.puts("")
  end
end

# Run the test
ConcurrentOrchestrationTest.run()
